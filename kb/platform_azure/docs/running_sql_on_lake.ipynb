{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd00626a5ce8a9d5b67f922e8e4b6ebb8a64c7d8489aadcd2d645a806c0624913d3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0626a5ce8a9d5b67f922e8e4b6ebb8a64c7d8489aadcd2d645a806c0624913d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# References\n",
    "\n",
    "* http://peter-hoffmann.com/2020/clients-and-data-access-with-turbodbc-to-azure-synapse-sql-on-demand.html\n",
    "* https://docs.microsoft.com/en-us/azure/synapse-analytics/sql/develop-storage-files-storage-access-control?tabs=shared-access-signature#supported-storage-authorization-types\n",
    "\n",
    "# Azure Setup with SQL User (database user with password)\n",
    "\n",
    "Summary of steps:\n",
    "\n",
    "**Azure Container UI**\n",
    "* Go to the storage container\n",
    "* Go to **shared access signature**\n",
    "* Select **key 1** and the permission your database user should have on the storage container\n",
    "* Click **Generate SAS Token and URL**\n",
    "* Pay attention to the **SAS Token** and **URL value** that will be generated below after your Click\n",
    "\n",
    "**AZURE Synpase Studio**\n",
    "* Go to the sql serverless pool sql editor in synapse, select built-in and db master (or other pool if you are using another sql pool)\n",
    "* Replace **<sas_token>** and **<url_value>** below with the generated values from step aboves\n",
    "\n",
    "**SQL to create a database user with password in sql pool inside synapse**\n",
    "```sql\n",
    "CREATE LOGIN testuser WITH password='xxx';\n",
    "```\n",
    "\n",
    "**SQL to give database user access to the storage container**\n",
    "```sql\n",
    "DROP CREDENTIAL [<url_value>]\n",
    "CREATE CREDENTIAL [<url_value>]\n",
    "WITH IDENTITY='SHARED ACCESS SIGNATURE'\n",
    ", SECRET = '<sas_token>';\n",
    "GO\n",
    "USE master\n",
    "GRANT REFERENCES ON CREDENTIAL::[<url_value>] TO [analyst4];\n",
    "```\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Connecting to the SQL Pool using Pydobc\n",
    "\n",
    "You can use the standard SQL Server ODBC driver for connecting to the Synapse SQL pool."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "\n",
    "server ='dyvenia-velux-ondemand.sql.azuresynapse.net'\n",
    "port = 1433\n",
    "database=\"acdb\"\n",
    "uid=\"analyst4\"\n",
    "pwd=\"12!jd1kdd303_\"\n",
    "#pwd=\"Toto!23!45672\"\n",
    "\n",
    "conn = pyodbc.connect(driver= 'ODBC Driver 17 for SQL Server', server=server, user=uid, password=pwd, database=database)\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "source": [
    "# Running SQL Code on CSV or PARQUET"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('country', ' sales'),\n",
       " ('italy', ' 100'),\n",
       " ('germany', ' 200'),\n",
       " ('spain', ' 50')]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "sql = \"\"\"select *\n",
    "from openrowset(\n",
    "    bulk 'https://dyvenia.blob.core.windows.net/testing/test/data.csv',\n",
    "    format = 'CSV',\n",
    "    parser_version = '2.0') as rows\n",
    "    \"\"\"\n",
    "cursor.execute(sql)\n",
    "cursor.fetchall()"
   ]
  },
  {
   "source": [
    "# Creating an External Table to Query via SQL from Python\n",
    "\n",
    "### Create a CREDENTIAL to allow access to the Storage Container\n",
    "\n",
    "```SQL\n",
    "USE [acdb]\n",
    "CREATE DATABASE SCOPED CREDENTIAL [<credential_name>]\n",
    "WITH IDENTITY='SHARED ACCESS SIGNATURE',  \n",
    "SECRET = '<Blob SAS token>';\n",
    "```\n",
    "### Create a DATA SOURCE using the above credential\n",
    "\n",
    "```sql\n",
    "USE [acdb]\n",
    "CREATE EXTERNAL DATA SOURCE SqlOnDemandDemo WITH (\n",
    "    LOCATION = 'https://<storage_name>.blob.core.windows.net/<container_name>',\n",
    "    CREDENTIAL = <credential_name>\n",
    ");\n",
    "```\n",
    "\n",
    "### Create File Formats\n",
    "\n",
    "Here we create 2: one for csv, one for parquet.\n",
    "\n",
    "**CSV**\n",
    "\n",
    "```sql\n",
    "USE [acdb]\n",
    "CREATE EXTERNAL FILE FORMAT QuotedCsvWithHeaderFormat\n",
    "WITH (  \n",
    "    FORMAT_TYPE = DELIMITEDTEXT,\n",
    "    FORMAT_OPTIONS ( FIELD_TERMINATOR = ',', STRING_DELIMITER = '\"', FIRST_ROW = 1   )\n",
    ");\n",
    "```\n",
    "\n",
    "**PARQUET**\n",
    "\n",
    "```sql\n",
    "USE [acdb]\n",
    "CREATE EXTERNAL FILE FORMAT parquet\n",
    "WITH (  \n",
    "    FORMAT_TYPE = PARQUET\n",
    ");\n",
    "```\n",
    "\n",
    "### Create External Table\n",
    "\n",
    "Creating external table `sales` on `test/data.csv` in container `testing` (the container `testing` is defined in the above sql when creating the `DATA SOURCE`).\n",
    "\n",
    "**CSV Format**\n",
    "\n",
    "```sql\n",
    "USE [acdb];\n",
    "GO\n",
    "CREATE EXTERNAL TABLE sales\n",
    "(\n",
    "    [country] VARCHAR (100),\n",
    "    [sales] FLOAT\n",
    ")\n",
    "WITH (\n",
    "    LOCATION = 'test/data.csv',\n",
    "    DATA_SOURCE = SqlOnDemandDemo,\n",
    "    FILE_FORMAT = QuotedCsvWithHeaderFormat\n",
    ");\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Using the External Table\n",
    "\n",
    "After creating the external table `sales` we can use it from Python running standard sql on it. Note how we can create a `calculated field` now as if we were using normal sql code."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('italy', 100.0, 200.0), ('germany', 200.0, 400.0), ('spain', 50.0, 100.0)]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "sql = \"\"\"select country, sales, sales * 2 as two_sales from sales\"\"\"\n",
    "cursor.execute(sql)\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}